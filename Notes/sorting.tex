\section{Sorting algorithms}

In this section I will revisit the four sorting algorithms that are must-know for coding interviews.
I will start with some basic considerations on what to look for on a sorting algorithm and why there is not a \emph{perfect} sorting algorithm.
After that, I visit the four most commonly used in coding interviews.
For each of them, I will show the general algorithm in pseudocode and then two implementations:
\begin{enumerate}
 \item An implementation using arrays since this is the easiest to understand.
 \item An implementation using the \href{https://en.wikibooks.org/wiki/More_C\%2B\%2B_Idioms/Iterator_Pair}{iterator idiom} in C++. Since this is the trickiest, and therefore asked in many interview questions.
\end{enumerate}

\subsection{Desired properties for sorting algorithms}

The sorting problem states that: Given a \emph{collection} (very likely and array) of $n$ \emph{elements} (usually assumed to be numbers, without loss of generality) and an \emph{order} defined on the elements (a way of telling for each two of them who is the lesser or if they are equal), we are interested in an algorithms that is able to return a permutation $(e_1, e_2, \ldots, e_n)$ of the elements in the collection such that $e_i \leq e_{i + 1}$, for $i \in [1, n-1]$

It is shown in any Computer Science class on Algorithms that theoretically the best running time we can achieve for a sorting algorithm is $O(n \cdot \lg n)$.

This is true only when we have \emph{certain} considerations for the computation model and the input. The most important are:

\begin{itemize}
 \item That we do not impose any restrictions on the input data. Particularly, we do not assume that the input entries are in any specific range. Nor that they are arriving at a certain time.
 \item That the algorithm is based on comparisons. In other words: the computer is only able to take \emph{two} elements at a time, from the input to compare them.
\end{itemize}

Assuming, that we have the two condition above, we are interested on an algorithm that is able to to sort the input data. 
The algorithms can have many desired properties, but the ones that we are usually interested are:

\begin{description}
 \item[Optimal] The algoritm runs in $O(n \cdot \lg n)$, for all valid inputs.
 \item[In place] The algorithm only requieres a constant $O(1)$ amount of extra space to operate.
 \item[Stable] If some elements of the input are equall, in the output those elements appear on the same order as they were in the input.
\end{description}

There has not been discover a \emph{simple} algorithm that has all these properties\footnote{Algorithms that have all these properites indeed exist. See for example \href{https://en.wikipedia.org/wiki/Block_sort}{block sort}. But they are very complex and no one will be expected to know them in a normal coding interiview}.
However, we have in particular four algorithms that have some of this properites, we can see a summary in Table~\ref{tab:sorting}.

\begin{table}[htb]
  \begin{center}
    \begin{tabular}{l | r r r | l}
      Algorithm & Optimal & In place & Stable & Comment\\
      \midrule
      Selection sort & No & Yes & No & Always runs in $O(n^2)$, but it's very easy to implement\\
      Quicksort & No & Yes & No & On average runs in $O(n \cdot \lg n)$. The worst case it's $O(n^2)$ \\
      Mergesort & Yes & No & Yes & It requieres $O(n)$ extra memory\\
      Heapsort & Yes & Yes & No & \\
    \end{tabular}
  \end{center}
\caption{Summary of the properities of the exposed algorithms}
\label{tab:sorting}
\end{table}

\subsection{Selection sort}

This is one of the simplest algorithms for sorting that exist.
If a novice programmer that has never taken a class on algorithms is asked to create a sorting algorithm, chances are that it will come up with selection sort.
The value for a coding interview is like some sort of \emph{panic sort}.

If you are tasked to create an algorithm that at some point requires sorting; and your interviewer asks you to implement to the smallest detail (which is very unlikely to happen).
You can always default back to insertion sort if you do not want to spend precious time thinking on the sorting part.
That is after saying to your interviewer that you know this is a bad algorithm, and you are using it \emph{only} because you do not have more time.

Having said that, if you face a problem where sorting is an essential part of the answer, using selection sort is a \emph{very bad} solution.

In essence, selection sort uses one simple fact:

The best way to find the minimum (or maximum for that matters) element of an array, takes $O(n)$ and it is the following:
\begin{enumerate}
 \item Assume that the minimum is the first element of the array.
 \item Compare the next element to the minimum. If that element is smaller, mark it as the new minimum.
 \item Continue doing the previous step until you reach the end of the array.
\end{enumerate}

Now that we know this simple fact, selection sort is very simple.

\begin{enumerate}
 \item Find the minimum element of the array.
 \item If the minimum is not at the beginning of the array, swap the minimum with the first element of the array.
 \item Assume that you have now a smaller array consisting of the second element of the array until the end.
 \item Repeat from step 1 until you don't have any more elements.
\end{enumerate}

Indeed selection sort have this name because at each step you \emph{select} the minimun element to place it at his corresponding place.

The Algorithm~\ref{alg:selectionsort} shows the formal details to implement selection sort.
To make the pseudocode easier I assume a zero based indexing.
In other words the first element of the array $V$ is $v_0$ and the last element is $v_{n-1}$

\begin{algorithm}[H]
\caption{Selection sort}
\label{alg:selectionsort}
\begin{algorithmic}[1] % El número le dice al entorno desde que número empezar a contar. Si le pones 0 omite los números
\Require $V = \{ v_0, v_1, \ldots, v_{n-1} \} $ \Comment{An array $V$ of size $n$}
\Ensure $V\text{ such that } v_i \leq v_{i + 1}, \forall i \in [0, n-2]$ \Comment{The array $V$ with his elements sorted}
\Procedure{InsertionSort}{$V$}
\For{$j \gets 1 \textbf{ to } n-1 \textbf{ step } 1$}
    \State $\text{min} \gets j$ \Comment{Assume the minimum is at the start}
    \For{$i \gets j+1 \textbf{ to } n-1 \textbf{ step } 1$} \Comment{Search for the actual minimum in the remainder of the interval}
        \If {$v_i < v_{\text{min}}$}
            \State $\text{min} \gets i$
        \EndIf
    \EndFor
    \If {$\text{min} \neq j$} \Comment{If the minimum it's not at the start}
        \State $\text{min} \leftrightarrow j$ \Comment{swap the two elements}
    \EndIf
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

The Listing~\ref{lst:selectionsort} shows the implementation on actual C++ code using arrays. Or \mintinline{cpp}{std::vector}s to be more precise.
To be complete the Listing~\ref{lst:selectionsort} also shows an implementation of   insertion sort in C++ using iterators.

\begin{listing}
\inputminted[
  firstline=7, %If you omit this two fields, the whole file is pulled
  lastline=23
  ]{cpp}{src/sortAlgorithms.cpp}
  \caption{An implementation of insertion sort in C++ using a vector}\label{lst:selectionsort}
\end{listing}

\begin{listing}
\inputminted[
  firstline=42, %If you omit this two fields, the whole file is pulled
  lastline=59
  ]{cpp}{src/sortAlgorithms.h}
  \caption{An implementation of insertion sort in C++ using iterators}\label{lst:selectionsortiter}
\end{listing}
 
\subsection{Quicksort}

This algorithm is one of the most used algorithms in the world.
To be more precise \emph{quicksort} is a family of algorithms.
The base idea remains the same in all of them.
However, the way different algorithms of the family made the so-called \emph{partition} changes.
Such change in the partition has implications on the running time.

The two most dominant schemes of partition are Lobuto and Ohare.
Since we are studying for an interview, we are going to be using Lobuto, since the code is cleaner.
That being said, Ohare's scheme is considered a more efficient algorithm.

First we present the basic idea behind all quicksort families.

\begin{enumerate}
 \item If the array to be sorted has less than 2 elements, it is already sorted; you do not need to do anything just return.
 \item Partition the array into two parts and a pivot. The first part contains all the elements smaller than the pivot, the second part contains all the elements greater than the pivot (elements equal to the pivot can go in either part)
 \item Then you can recursively use quicksort to order the two remaing parts.
\end{enumerate}

In this pseudocode I will use a zero based indexing again, that is the first element of the array $V$ is $v_0$ and the last element is $v_{n-1}$.
Also we will use indices to keep track of the interval of the original array we are sorting.
Those intervals are defined by two indices in the original array.

For defining the intervals, I use the begin and end convention.
On this convention the first index is the \emph{first} element of the interval, the second element is \emph{one pass the last} element of the interval.
For example the indices $i$, $j$, where $i \leq j$, define the interval $[i, j)$ whose first element is $v_i$ and last element is $v_{j-1}$

Since this is a recursive algorithm the first call to sort the whole array will need to be called with indices $0$ and $n$ for an array $V$ of $n$ elements

\begin{algorithm}[H]
\caption{Quicksort}
\label{alg:quicksort}
\begin{algorithmic}[1] % El número le dice al entorno desde que número empezar a contar. Si le pones 0 omite los números
\Require $V = \{ v_0, v_1, \ldots, v_{n-1} \} $ and $[b,e)$ \Comment{An array $V$ of size $n$, and an inerval $[b,e)$ with $0 \leq b \leq e \leq n$}
\Ensure $V\text{ such that } v_i \leq v_{i + 1}, \forall i \in [0, n-2]$ \Comment{The array $V$ with his elements sorted}
\Procedure{QuickSort}{$V$, $b$, $e$} \Comment{$b$ stands for \emph{begin} and $e$ for \emph{end}}
    \If {$e - b > 1$} \Comment{If the interval contains more than one element}
        \State $p \gets$ \Call{Partition}{$V$, $b$, $e$} \label{endPartition} \Comment{Make a partition of $V$ and get the partition point $p$}
        \State \Call{QuickSort}{$V$, $b$, $p$} \Comment{Order one half}
        \State \Call{QuickSort}{$V$, $p + 1$, $e$} \Comment{Order one other half}
    \EndIf
\EndProcedure
\Procedure{Partition}{$V$, $l$, $r$} \Comment{$l$ stands for \emph{left} and $r$ for \emph{right}}
\State $j \gets r - 1$ \label{pivotPlace} \Comment{$j$ stores the index of the pivot}
\State $p \gets l$ \Comment{$p$ stores the \emph{partition point}}
\For{$i \gets l \textbf{ to } j-1 \textbf{ step } 1$} \Comment{We traverse the interval minus the pivot (which it's at the end)}
    \If {$v_i \leq v_j$} \Comment{If this element is smaller than the pivot}
        \State $v_p \leftrightarrow v_i$ \Comment{swap it with the one at the partition point}
        \State $p \gets p + 1$ \Comment{Move the partition point}
    \EndIf
\EndFor
\State $v_p \leftrightarrow v_j$ \Comment{Put the pivot in his corresponding place}
\State \Return $p$ \Comment{return the partition point}
\EndProcedure
\end{algorithmic}
\end{algorithm}

A couple of remarks to clarify the above pseudocode.
\begin{itemize}
 \item After the call to \emph{partition} in line~\ref{endPartition}, the only element we can guarantee to be at his corresponding place (in the ordered array) is the pivot.
 \item In Loboto's partition scheme, we choose the last element of the interval to be the \emph{pivot} element.
 \item The variable $j$ on line~\ref{pivotPlace} it's not really needed. It just makes the code easier to read by marking the initial place of the pivot.
 \item The variable $p$ is the \emph{partition point}: the place at which the pivot will be at the end of the partition procedure.
 \item The way the scheme works is \emph{assuming} that all the elements less than the pivot are to the left of $p$. If we found some element that it is not, then we change his place and move $p$ (Since now we have another element that should be at his left).
\end{itemize}

The code using an array is strightfoward to implement and is shown in two parts: The Listing~\ref{lst:quicksortArray} shows the main quicksort function and the Listing~\ref{lst:partitionArray} shows the partition scheme (Lobuto).

\begin{listing}
\inputminted[
  firstline=52, %If you omit this two fields, the whole file is pulled
  lastline=69
  ]{cpp}{src/sortAlgorithms.cpp}
  \caption{An implementation of quicksort in C++ using an array}\label{lst:quicksortArray}
\end{listing}

\begin{listing}
\inputminted[
  firstline=25, %If you omit this two fields, the whole file is pulled
  lastline=51
  ]{cpp}{src/sortAlgorithms.cpp}
  \caption{The partition (Lobuto) used by quicksort in C++}\label{lst:partitionArray}
\end{listing}

Since we already have the range defined in a very similar way to that of an iterator. 
The code to implement both functions using C++ iterators it's very similar.
Listing~\ref{lst:quicksortIterator} shows the implementation of the main function and Listing~\ref{lst:partitionIterator} the partition scheme.

\begin{listing}
\inputminted[
  firstline=27, %If you omit this two fields, the whole file is pulled
  lastline=40
  ]{cpp}{src/sortAlgorithms.h}
  \caption{An implementation of quicksort in C++ using iterators}\label{lst:quicksortIterator}
\end{listing}

\begin{listing}
\inputminted[
  firstline=3, %If you omit this two fields, the whole file is pulled
  lastline=25
  ]{cpp}{src/sortAlgorithms.h}
  \caption{Lobuto's partition using iterators}\label{lst:partitionIterator}
\end{listing}
